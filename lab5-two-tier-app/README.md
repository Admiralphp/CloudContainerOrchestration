# Lab 5 - Two Tier Application sur K3s

## 1. PrÃ©sentation du projet

Ce projet implÃ©mente une application web simple (formulaire nom / email)
connectÃ©e Ã  une base de donnÃ©es MySQL. L'objectif est de dÃ©ployer une
architecture deux-tiers sur un cluster K3s avec deux Deployments et deux Services
(NodePort pour le web, ClusterIP pour la base de donnÃ©es).

## 2. Architecture

- Frontend : Flask (Python), exposÃ© via un Service de type NodePort
- Backend : MySQL (image officielle), exposÃ© via un Service de type ClusterIP
- Les paramÃ¨tres de connexion (host, user, password, database) sont fournis
  sous forme de variables d'environnement directement dans les manifests YAML.

Le schÃ©ma ci-dessous illustre l'architecture (fichier `docs/architecture.png`) :

Client (navigateur) â†’ Service Web (NodePort 30080) â†’ Pods Flask
Pods Flask â†’ Service DB (ClusterIP 3306) â†’ Pod MySQL

## 3. PrÃ©requis

- Cluster K3s fonctionnel (kubectl configurÃ©)
- Docker (pour builder et pousser l'image)
- AccÃ¨s Ã  un registre d'images (ex: Docker Hub)
- Nom d'image utilisÃ© : `mohamedessid/lab5-web:1.0`

## 4. Ã‰tapes de dÃ©ploiement

```bash
# Build + push + dÃ©ploiement
./scripts/install.sh

# VÃ©rification des ressources
kubectl get all -n lab5-app
```

## 5. Test de l'application

1. IP du nÅ“ud K3s : `10.174.154.67`
2. AccÃ©der Ã  : `http://10.174.154.67:30085/`
3. Remplir le formulaire (nom, email) et valider.
4. VÃ©rifier que les donnÃ©es apparaissent dans la table des enregistrements.

### ðŸ“¸ Captures d'Ã©cran de validation

Toutes les captures d'Ã©cran sont disponibles dans le dossier [`docs/screenshots/`](docs/screenshots/).

**DÃ©ploiement et Configuration :**
- [Installation complÃ¨te](https://github.com/Admiralphp/CloudContainerOrchestration/blob/main/lab5-two-tier-app/docs/screenshots/install-sh.png)
- [Cluster K3s opÃ©rationnel](https://github.com/Admiralphp/CloudContainerOrchestration/blob/main/lab5-two-tier-app/docs/screenshots/01-cluster-nodes.png)
- [Ressources dÃ©ployÃ©es](https://github.com/Admiralphp/CloudContainerOrchestration/blob/main/lab5-two-tier-app/docs/screenshots/02-deployed-resources.png)
- [Status des pods](https://github.com/Admiralphp/CloudContainerOrchestration/blob/main/lab5-two-tier-app/docs/screenshots/03-pods-status.png)
- [Logs application web](https://github.com/Admiralphp/CloudContainerOrchestration/blob/main/lab5-two-tier-app/docs/screenshots/04-web-logs.png)
- [Logs base de donnÃ©es](https://github.com/Admiralphp/CloudContainerOrchestration/blob/main/lab5-two-tier-app/docs/screenshots/05-db-logs.png)

**Tests Fonctionnels :**
- [Interface web vide](https://github.com/Admiralphp/CloudContainerOrchestration/blob/main/lab5-two-tier-app/docs/screenshots/06-web-interface-empty.png)
- [Formulaire rempli](https://github.com/Admiralphp/CloudContainerOrchestration/blob/main/lab5-two-tier-app/docs/screenshots/07-form-filled.png)
- [DonnÃ©es insÃ©rÃ©es](https://github.com/Admiralphp/CloudContainerOrchestration/blob/main/lab5-two-tier-app/docs/screenshots/08-data-inserted.png)
- [Plusieurs enregistrements](https://github.com/Admiralphp/CloudContainerOrchestration/blob/main/lab5-two-tier-app/docs/screenshots/09-multiple-records.png)
- [VÃ©rification base de donnÃ©es](https://github.com/Admiralphp/CloudContainerOrchestration/blob/main/lab5-two-tier-app/docs/screenshots/10-db-verification.png)

## 6. Structure du projet

```text
lab5-two-tier-app/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ templates/
â”‚       â””â”€â”€ index.html
â”œâ”€â”€ k8s/
â”‚   â”œâ”€â”€ namespace.yaml
â”‚   â”œâ”€â”€ db-configmap.yaml      # STEP 2: Configuration non sensible
â”‚   â”œâ”€â”€ web-configmap.yaml     # STEP 2: Configuration non sensible
â”‚   â”œâ”€â”€ db-secret.yaml         # STEP 2: Credentials sÃ©curisÃ©s
â”‚   â”œâ”€â”€ db-pv.yaml             # STEP 3: Persistent Volume
â”‚   â”œâ”€â”€ db-pvc.yaml            # STEP 3: Persistent Volume Claim
â”‚   â”œâ”€â”€ web-deployment.yaml
â”‚   â”œâ”€â”€ web-service.yaml
â”‚   â”œâ”€â”€ db-deployment.yaml     # STEP 3: Monte le PVC
â”‚   â””â”€â”€ db-service.yaml
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ install.sh
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ architecture.png
â”‚   â”œâ”€â”€ screenshots/
â”‚   â””â”€â”€ VALIDATION.md
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

## 7. Analyse Technique et Justifications

### 7.1 Architecture Deux-Tiers

Ce projet implÃ©mente une architecture deux-tiers classique sÃ©parant :

**Frontend (Web Tier)** :
- Application Flask (Python 3.12) avec interface web HTML
- 2 rÃ©plicas pour assurer la haute disponibilitÃ©
- ConteneurisÃ©e via Docker et dÃ©ployÃ©e sur Kubernetes
- Communique avec la base de donnÃ©es via variables d'environnement

**Backend (Data Tier)** :
- Base de donnÃ©es MySQL 8.0 (image officielle)
- 1 replica (suffisant pour un environnement de lab)
- Service ClusterIP pour isolation rÃ©seau
- Configuration dÃ©clarative des credentials et de la base de donnÃ©es

Cette sÃ©paration permet :
- **ScalabilitÃ©** : PossibilitÃ© d'augmenter les rÃ©plicas web indÃ©pendamment
- **MaintenabilitÃ©** : Mise Ã  jour du frontend sans toucher Ã  la base de donnÃ©es
- **SÃ©curitÃ©** : Isolation de la couche donnÃ©es derriÃ¨re un service interne

### 7.2 Choix de NodePort pour l'Exposition Web

**DÃ©cision** : Service de type `NodePort` sur le port 30085

**Justifications** :
1. **Environnement K3s** : K3s est souvent dÃ©ployÃ© sur des infrastructures locales ou edge oÃ¹ les LoadBalancers cloud (AWS ELB, Azure LB) ne sont pas disponibles
2. **SimplicitÃ©** : NodePort permet un accÃ¨s direct via `<IP_NODE>:30085` sans configuration supplÃ©mentaire
3. **DÃ©mo et Tests** : IdÃ©al pour des environnements de dÃ©veloppement et de laboratoire
4. **Pas de dÃ©pendances externes** : Fonctionne immÃ©diatement sans MetalLB ou autre solution de LoadBalancing

**Alternative Ã©cartÃ©e** : LoadBalancer aurait nÃ©cessitÃ© une infrastructure cloud ou l'installation de MetalLB.

### 7.3 Choix de ClusterIP pour la Base de DonnÃ©es

**DÃ©cision** : Service de type `ClusterIP` pour MySQL

**Justifications** :
1. **Principe de sÃ©curitÃ©** : La base de donnÃ©es ne doit JAMAIS Ãªtre exposÃ©e publiquement
2. **AccÃ¨s restreint** : Seuls les pods du cluster peuvent communiquer avec le service `db-service`
3. **RÃ©duction de la surface d'attaque** : PrÃ©vient les accÃ¨s non autorisÃ©s depuis l'extÃ©rieur
4. **Best Practice** : Configuration standard pour les backends de donnÃ©es dans Kubernetes

**BÃ©nÃ©fices** :
- Protection contre les attaques externes
- Communication interne rapide via le rÃ©seau overlay de Kubernetes
- DÃ©couverte de service automatique via DNS interne (`db-service.lab5-app.svc.cluster.local`)

### 7.4 Gestion de la Configuration via Variables d'Environnement

**Approche** : Variables dÃ©finies directement dans les manifests YAML (deployment)

**ParamÃ¨tres Web App** :
```yaml
- name: DB_HOST
  value: "db-service"
- name: DB_PORT
  value: "3306"
- name: DB_USER
  value: "appuser"
- name: DB_PASSWORD
  value: "apppassword"
- name: DB_NAME
  value: "appdb"
```

**ParamÃ¨tres MySQL** :
```yaml
- name: MYSQL_ROOT_PASSWORD
  value: "rootpassword"
- name: MYSQL_DATABASE
  value: "appdb"
- name: MYSQL_USER
  value: "appuser"
- name: MYSQL_PASSWORD
  value: "apppassword"
```

**Justifications pour ce LAB** :
1. **SimplicitÃ© pÃ©dagogique** : Facilite la comprÃ©hension des dÃ©butants
2. **VisibilitÃ©** : Toute la configuration est visible dans un seul fichier
3. **ConformitÃ© au LAB** : L'Ã©noncÃ© spÃ©cifie explicitement "pas de ConfigMaps ni Secrets"
4. **DÃ©bogage facile** : Modification rapide pour tests et validation

**Ã‰volution future recommandÃ©e** :
- Production : Utiliser des **Secrets** Kubernetes pour les mots de passe
- Centralisation : Migrer vers des **ConfigMaps** pour les paramÃ¨tres non sensibles
- SÃ©curitÃ© renforcÃ©e : IntÃ©gration avec **HashiCorp Vault** ou **Azure Key Vault**

### 7.5 Namespace DÃ©diÃ©

**DÃ©cision** : DÃ©ploiement dans le namespace `lab5-app`

**Avantages** :
- **Isolation logique** : SÃ©paration des ressources du LAB 5 des autres projets
- **Gestion simplifiÃ©e** : `kubectl delete namespace lab5-app` supprime tout proprement
- **Organisation** : Facilite la visualisation avec `kubectl get all -n lab5-app`
- **Quotas potentiels** : PossibilitÃ© d'appliquer des ResourceQuotas par namespace

---

## STEP 2 : ConfigMaps et Secrets pour AmÃ©lioration de la SÃ©curitÃ©

### 8.1 Objectif

AmÃ©liorer la configuration et la sÃ©curitÃ© en introduisant :
- **ConfigMaps** : Pour les paramÃ¨tres de configuration non sensibles
- **Secrets** : Pour les credentials et mots de passe

### 8.2 ConfigMaps CrÃ©Ã©s

#### `db-configmap.yaml`
```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: db-config
  namespace: lab5-app
data:
  MYSQL_DATABASE: "appdb"
```

**Utilisation** : Stocke le nom de la base de donnÃ©es (non sensible)

#### `web-configmap.yaml`
```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: web-config
  namespace: lab5-app
data:
  DB_HOST: "db-service"
  DB_PORT: "3306"
  DB_NAME: "appdb"
```

**Utilisation** : Stocke les paramÃ¨tres de connexion (host, port, nom de DB)

### 8.3 Secret CrÃ©Ã©

#### `db-secret.yaml`
```yaml
apiVersion: v1
kind: Secret
metadata:
  name: db-secret
  namespace: lab5-app
type: Opaque
data:
  MYSQL_ROOT_PASSWORD: cm9vdHBhc3N3b3Jk    # rootpassword (base64)
  MYSQL_USER: YXBwdXNlcg==                 # appuser (base64)
  MYSQL_PASSWORD: YXBwcGFzc3dvcmQ=         # apppassword (base64)
  DB_PASSWORD: YXBwcGFzc3dvcmQ=            # apppassword (base64)
  DB_USER: YXBwdXNlcg==                    # appuser (base64)
```

**Note** : Les valeurs sont encodÃ©es en base64 pour la sÃ©curitÃ©.

### 8.4 Modification des Deployments

#### Dans `db-deployment.yaml` :
```yaml
env:
  - name: MYSQL_ROOT_PASSWORD
    valueFrom:
      secretKeyRef:
        name: db-secret
        key: MYSQL_ROOT_PASSWORD
  - name: MYSQL_DATABASE
    valueFrom:
      configMapKeyRef:
        name: db-config
        key: MYSQL_DATABASE
  - name: MYSQL_USER
    valueFrom:
      secretKeyRef:
        name: db-secret
        key: MYSQL_USER
  - name: MYSQL_PASSWORD
    valueFrom:
      secretKeyRef:
        name: db-secret
        key: MYSQL_PASSWORD
```

#### Dans `web-deployment.yaml` :
```yaml
env:
  - name: DB_HOST
    valueFrom:
      configMapKeyRef:
        name: web-config
        key: DB_HOST
  - name: DB_PORT
    valueFrom:
      configMapKeyRef:
        name: web-config
        key: DB_PORT
  - name: DB_USER
    valueFrom:
      secretKeyRef:
        name: db-secret
        key: DB_USER
  - name: DB_PASSWORD
    valueFrom:
      secretKeyRef:
        name: db-secret
        key: DB_PASSWORD
  - name: DB_NAME
    valueFrom:
      configMapKeyRef:
        name: web-config
        key: DB_NAME
```

### 8.5 Avantages de cette Approche

#### SÃ©curitÃ© AmÃ©liorÃ©e
- **Secrets encodÃ©s** : Les mots de passe ne sont plus en clair dans les YAML
- **RBAC possible** : ContrÃ´le d'accÃ¨s granulaire aux Secrets
- **Chiffrement au repos** : Les Secrets peuvent Ãªtre chiffrÃ©s dans etcd

#### Gestion CentralisÃ©e
- **Single Source of Truth** : Une seule ConfigMap/Secret pour plusieurs deployments
- **Mise Ã  jour facilitÃ©e** : Modification centralisÃ©e sans redÃ©ployer les pods
- **RÃ©utilisabilitÃ©** : Partage de configuration entre plusieurs applications

#### SÃ©paration des ResponsabilitÃ©s
- **DevOps** : GÃ¨re les ConfigMaps (configuration applicative)
- **SecOps** : GÃ¨re les Secrets (credentials sensibles)
- **DÃ©veloppeurs** : Se concentrent sur le code, pas sur la configuration

#### Environnements Multiples
- ConfigMaps/Secrets diffÃ©rents par environnement (dev, staging, prod)
- MÃªme code de dÃ©ploiement, configuration adaptÃ©e
- Facilite le CI/CD

### 8.6 Commandes de DÃ©ploiement STEP 2

```bash
# 1. CrÃ©er le namespace
kubectl apply -f k8s/namespace.yaml

# 2. CrÃ©er les ConfigMaps
kubectl apply -n lab5-app -f k8s/db-configmap.yaml
kubectl apply -n lab5-app -f k8s/web-configmap.yaml

# 3. CrÃ©er les Secrets
kubectl apply -n lab5-app -f k8s/db-secret.yaml

# 4. DÃ©ployer les applications
kubectl apply -n lab5-app -f k8s/db-deployment.yaml
kubectl apply -n lab5-app -f k8s/db-service.yaml
kubectl apply -n lab5-app -f k8s/web-deployment.yaml
kubectl apply -n lab5-app -f k8s/web-service.yaml

# 5. VÃ©rifier les ConfigMaps et Secrets
kubectl get configmaps -n lab5-app
kubectl get secrets -n lab5-app
kubectl describe configmap web-config -n lab5-app
kubectl describe secret db-secret -n lab5-app
```

### 8.7 VÃ©rification de la Configuration

```bash
# Voir les variables d'environnement d'un pod web
kubectl exec -n lab5-app deployment/web-deployment -- env | grep DB

# Voir les variables d'environnement du pod MySQL
kubectl exec -n lab5-app deployment/db-deployment -- env | grep MYSQL
```

### 8.8 GÃ©nÃ©ration des Valeurs Base64 pour Secrets

Si vous devez changer les mots de passe, utilisez :

```bash
# Linux/Mac
echo -n "nouveaumotdepasse" | base64

# Windows PowerShell
[Convert]::ToBase64String([Text.Encoding]::UTF8.GetBytes("nouveaumotdepasse"))
```

### 8.9 Rotation des Secrets

Pour mettre Ã  jour un mot de passe :

```bash
# 1. Ã‰diter le Secret
kubectl edit secret db-secret -n lab5-app

# 2. RedÃ©marrer les pods pour charger le nouveau Secret
kubectl rollout restart deployment/web-deployment -n lab5-app
kubectl rollout restart deployment/db-deployment -n lab5-app
```

---

## STEP 3 : Persistent Volumes (PV) et Persistent Volume Claims (PVC)

### 9.1 Objectif

Assurer la **persistance des donnÃ©es** de la base de donnÃ©es MySQL mÃªme en cas de :
- RedÃ©marrage des pods
- Suppression accidentelle du deployment
- Migration vers un autre nÅ“ud du cluster

Sans PV/PVC, les donnÃ©es MySQL sont perdues Ã  chaque redÃ©marrage du pod car elles sont stockÃ©es dans le systÃ¨me de fichiers Ã©phÃ©mÃ¨re du conteneur.

### 9.2 Architecture de Stockage

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           MySQL Pod                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Container: mysql:8.0             â”‚  â”‚
â”‚  â”‚  Volume Mount: /var/lib/mysql     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                 â”‚                        â”‚
â”‚                 â–¼                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Volume: mysql-storage            â”‚  â”‚
â”‚  â”‚  Source: PVC (mysql-pvc)          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  PersistentVolumeClaim          â”‚
   â”‚  Name: mysql-pvc                â”‚
   â”‚  Request: 1Gi                   â”‚
   â”‚  StorageClass: local-path       â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  PersistentVolume               â”‚
   â”‚  Name: mysql-pv                 â”‚
   â”‚  Capacity: 2Gi                  â”‚
   â”‚  Path: /data/mysql (host)       â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 9.3 Persistent Volume (PV)

#### `db-pv.yaml`
```yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: mysql-pv
  namespace: lab5-app
spec:
  capacity:
    storage: 2Gi
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  storageClassName: local-path
  hostPath:
    path: /data/mysql
    type: DirectoryOrCreate
```

**CaractÃ©ristiques** :
- **CapacitÃ©** : 2Gi (supÃ©rieur au PVC pour avoir de la marge)
- **Access Mode** : `ReadWriteOnce` (un seul nÅ“ud peut monter en lecture/Ã©criture)
- **Reclaim Policy** : `Retain` (les donnÃ©es sont conservÃ©es aprÃ¨s suppression du PVC)
- **StorageClass** : `local-path` (compatible K3s par dÃ©faut)
- **HostPath** : `/data/mysql` sur le nÅ“ud K3s

### 9.4 Persistent Volume Claim (PVC)

#### `db-pvc.yaml`
```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: mysql-pvc
  namespace: lab5-app
spec:
  accessModes:
    - ReadWriteOnce
  storageClassName: local-path
  resources:
    requests:
      storage: 1Gi
```

**Utilisation** :
- **Demande** : 1Gi de stockage
- **Binding** : Kubernetes lie automatiquement ce PVC au PV `mysql-pv`
- **Namespace** : `lab5-app` (doit correspondre au deployment)

### 9.5 Modification du Deployment MySQL

#### Ajout dans `db-deployment.yaml` :
```yaml
spec:
  template:
    spec:
      containers:
        - name: mysql
          image: mysql:8.0
          volumeMounts:
            - name: mysql-storage
              mountPath: /var/lib/mysql    # RÃ©pertoire de donnÃ©es MySQL
      volumes:
        - name: mysql-storage
          persistentVolumeClaim:
            claimName: mysql-pvc            # RÃ©fÃ©rence au PVC
```

**Explication** :
- **volumeMounts** : Monte le volume dans le conteneur Ã  `/var/lib/mysql`
- **volumes** : DÃ©finit le volume comme source le PVC `mysql-pvc`
- MySQL stocke ses bases de donnÃ©es, tables et logs dans `/var/lib/mysql`

### 9.6 Avantages de la Persistance

#### 1. **DurabilitÃ© des DonnÃ©es**
- Les donnÃ©es survivent aux redÃ©marrages de pods
- Protection contre les suppressions accidentelles
- Backup facilitÃ© (sauvegarde du volume)

#### 2. **Haute DisponibilitÃ©**
- Migration de pod vers un autre nÅ“ud sans perte de donnÃ©es (avec stockage rÃ©seau)
- RÃ©silience face aux pannes matÃ©rielles

#### 3. **ScalabilitÃ©**
- PossibilitÃ© d'augmenter la taille du volume
- Changement de StorageClass sans refaire le deployment

#### 4. **SÃ©paration du Stockage**
- Cycle de vie indÃ©pendant : PV/PVC vs Deployment
- Plusieurs deployments peuvent utiliser le mÃªme PVC (selon AccessMode)

#### 5. **Production Ready**
- Conforme aux best practices Kubernetes
- Compatible avec tous les cloud providers (AWS EBS, Azure Disk, GCP PD)

### 9.7 Types d'Access Modes

| Access Mode | Description | Cas d'usage |
|-------------|-------------|-------------|
| **ReadWriteOnce (RWO)** | Lecture/Ã©criture par un seul nÅ“ud | MySQL, PostgreSQL (1 replica) |
| **ReadOnlyMany (ROX)** | Lecture seule par plusieurs nÅ“uds | Assets statiques, configurations |
| **ReadWriteMany (RWX)** | Lecture/Ã©criture par plusieurs nÅ“uds | NFS, applications distribuÃ©es |

**Notre choix** : `ReadWriteOnce` car MySQL ne supporte pas l'Ã©criture concurrente.

### 9.8 StorageClass dans K3s

K3s inclut par dÃ©faut le provisioner **local-path** :

```bash
# VÃ©rifier les StorageClasses disponibles
kubectl get storageclass

# RÃ©sultat attendu :
# NAME                   PROVISIONER             RECLAIMPOLICY   VOLUMEBINDINGMODE      AGE
# local-path (default)   rancher.io/local-path   Delete          WaitForFirstConsumer   10d
```

**local-path** :
- Stockage sur le systÃ¨me de fichiers local du nÅ“ud
- IdÃ©al pour environnements de dÃ©veloppement et K3s
- Pour production cloud : utiliser AWS EBS, Azure Disk, etc.

### 9.9 Commandes de DÃ©ploiement STEP 3

```bash
# 1. CrÃ©er le Persistent Volume
kubectl apply -f k8s/db-pv.yaml

# 2. CrÃ©er le Persistent Volume Claim
kubectl apply -n lab5-app -f k8s/db-pvc.yaml

# 3. VÃ©rifier le binding PV â†” PVC
kubectl get pv
kubectl get pvc -n lab5-app

# 4. DÃ©ployer la base de donnÃ©es avec persistance
kubectl apply -n lab5-app -f k8s/db-deployment.yaml

# 5. VÃ©rifier le montage du volume
kubectl describe pod -n lab5-app -l app=db
```

### 9.10 VÃ©rification de la Persistance

#### Test de persistance des donnÃ©es :

```bash
# 1. InsÃ©rer des donnÃ©es dans l'application web
# Via http://10.174.154.67:30085/

# 2. VÃ©rifier les donnÃ©es dans MySQL
kubectl exec -n lab5-app deployment/db-deployment -- \
  mysql -uappuser -papppassword -e "SELECT * FROM appdb.people;"

# 3. Supprimer le pod MySQL (simulation de crash)
kubectl delete pod -n lab5-app -l app=db

# 4. Attendre que le pod redÃ©marre
kubectl wait --for=condition=ready pod -l app=db -n lab5-app --timeout=60s

# 5. VÃ©rifier que les donnÃ©es sont toujours prÃ©sentes
kubectl exec -n lab5-app deployment/db-deployment -- \
  mysql -uappuser -papppassword -e "SELECT * FROM appdb.people;"

# âœ… Les donnÃ©es doivent Ãªtre intactes !
```

### 9.11 Gestion du Volume

#### Voir la taille utilisÃ©e :
```bash
# Sur le nÅ“ud K3s
sudo du -sh /data/mysql
```

#### Nettoyer les donnÃ©es (attention : irrÃ©versible) :
```bash
# Supprimer le PVC (libÃ¨re le volume)
kubectl delete pvc mysql-pvc -n lab5-app

# Supprimer le PV
kubectl delete pv mysql-pv

# Supprimer les donnÃ©es sur le nÅ“ud
sudo rm -rf /data/mysql
```

#### Augmenter la taille du PVC :
```bash
# Ã‰diter le PVC
kubectl edit pvc mysql-pvc -n lab5-app

# Modifier spec.resources.requests.storage
# Exemple: 1Gi â†’ 5Gi
```

### 9.12 Reclaim Policies

| Policy | Comportement | Usage |
|--------|--------------|-------|
| **Retain** | DonnÃ©es conservÃ©es aprÃ¨s suppression PVC | Production (sauvegarde manuelle) |
| **Delete** | DonnÃ©es supprimÃ©es avec le PVC | DÃ©veloppement |
| **Recycle** | Volume rÃ©initialisÃ© et rÃ©utilisable | DÃ©prÃ©ciÃ© |

**Notre choix** : `Retain` pour Ã©viter les pertes de donnÃ©es accidentelles.

### 9.13 Backup des DonnÃ©es

```bash
# Backup MySQL vers un fichier
kubectl exec -n lab5-app deployment/db-deployment -- \
  mysqldump -uroot -prootpassword --all-databases > backup.sql

# Ou copier le volume directement
sudo tar -czf mysql-backup-$(date +%Y%m%d).tar.gz -C /data/mysql .
```

### 9.14 Limitations de HostPath

âš ï¸ **HostPath** (local-path) a des limitations :

1. **Pas de haute disponibilitÃ©** : Les donnÃ©es sont liÃ©es Ã  un nÅ“ud spÃ©cifique
2. **Migration impossible** : Si le pod change de nÅ“ud, le volume n'est pas accessible
3. **Pas de rÃ©plication** : Un seul point de dÃ©faillance

**Pour production multi-nÅ“uds**, utiliser :
- **NFS** : Stockage rÃ©seau partagÃ©
- **Ceph/Rook** : Stockage distribuÃ©
- **Cloud Storage** : AWS EBS, Azure Disk, GCP PD

---

## 10. Validation et Preuves de SuccÃ¨s

Consultez le document `docs/VALIDATION.md` pour :
- La checklist complÃ¨te de conformitÃ© avec l'Ã©noncÃ© du LAB
- Les instructions dÃ©taillÃ©es pour capturer les screenshots requis
- Les commandes de vÃ©rification Ã  exÃ©cuter
- La liste des 10 screenshots Ã  fournir dans `docs/screenshots/`

### Commandes de Validation Rapide

```bash
# VÃ©rifier que tous les pods sont Running
kubectl get pods -n lab5-app

# VÃ©rifier les services
kubectl get svc -n lab5-app

# Tester l'accÃ¨s web
curl http://10.174.154.67:30085/

# Consulter les logs
kubectl logs -n lab5-app deployment/web-deployment
kubectl logs -n lab5-app statefulset/postgres
```

---

## LAB 8 : Migration vers StatefulSet pour PostgreSQL

### 11.1 Pourquoi Migrer vers StatefulSet ?

#### Limitations des Deployments pour les Bases de DonnÃ©es

Dans les LABs prÃ©cÃ©dents (5-7), nous utilisions un **Deployment** pour MySQL/PostgreSQL. Cette approche fonctionne mais prÃ©sente plusieurs limitations :

| ProblÃ¨me | Impact | Exemple |
|----------|--------|---------|
| **Noms de pods alÃ©atoires** | `db-deployment-7f8d9-xyz12` change Ã  chaque restart | Impossible de cibler un pod spÃ©cifique |
| **Pas d'identitÃ© rÃ©seau stable** | Connexion impossible Ã  une instance prÃ©cise | RÃ©plication master-slave impossible |
| **Gestion manuelle des volumes** | CrÃ©ation manuelle PV/PVC requise | Erreurs humaines, complexitÃ© |
| **Pas d'ordre de dÃ©marrage** | Pods dÃ©marrent/s'arrÃªtent alÃ©atoirement | ProblÃ¨mes de synchronisation |
| **Scaling difficile** | Pas de coordination entre rÃ©plicas | Corruption de donnÃ©es possible |
| **Pas de rÃ©plication** | Configuration master-slave impossible | Pas de haute disponibilitÃ© |

#### Avantages des StatefulSets

StatefulSet est **spÃ©cifiquement conÃ§u** pour les applications stateful (bases de donnÃ©es, systÃ¨mes distribuÃ©s, clusters) :

| FonctionnalitÃ© | Description | BÃ©nÃ©fice |
|----------------|-------------|----------|
| **IdentitÃ© stable** | `postgres-0`, `postgres-1`, `postgres-2` | Noms prÃ©visibles et constants |
| **DNS stable** | `postgres-0.postgres-headless.lab5-app.svc.cluster.local` | Adressage direct d'un pod |
| **DÃ©ploiement ordonnÃ©** | SÃ©quentiel : 0 â†’ 1 â†’ 2 | Garantit l'ordre d'initialisation |
| **Suppression ordonnÃ©e** | Inverse : 2 â†’ 1 â†’ 0 | Graceful shutdown propre |
| **Volume automatique** | `volumeClaimTemplates` crÃ©e PVC par pod | Pas de gestion manuelle |
| **Storage persistant** | Chaque pod a son volume dÃ©diÃ© | DonnÃ©es conservÃ©es |
| **HA Ready** | Facilite master-slave, clustering | Production-ready |

### 11.2 Migration de MySQL vers PostgreSQL

Nous migrons Ã©galement de **MySQL vers PostgreSQL** pour des raisons de :
- **Performance** : Meilleur pour les applications complexes
- **Standards** : Meilleur support SQL standard
- **RÃ©plication** : Streaming replication native plus robuste
- **Extensions** : PostGIS, pg_stat_statements, etc.

### 11.3 Architecture LAB 8

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Kubernetes Cluster                        â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚         Namespace: lab5-app                            â”‚ â”‚
â”‚  â”‚                                                         â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚ â”‚
â”‚  â”‚  â”‚  Web Deployment  â”‚      â”‚  StatefulSet        â”‚   â”‚ â”‚
â”‚  â”‚  â”‚  (2 replicas)    â”‚â”€â”€â”€â”€â”€â”€â”‚  postgres           â”‚   â”‚ â”‚
â”‚  â”‚  â”‚                  â”‚      â”‚                      â”‚   â”‚ â”‚
â”‚  â”‚  â”‚  web-xxx-pod1    â”‚      â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚ â”‚
â”‚  â”‚  â”‚  web-xxx-pod2    â”‚      â”‚  â”‚  postgres-0   â”‚  â”‚   â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚  â”‚  (primary)    â”‚  â”‚   â”‚ â”‚
â”‚  â”‚           â”‚                 â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚ â”‚
â”‚  â”‚           â”‚                 â”‚         â”‚           â”‚   â”‚ â”‚
â”‚  â”‚           â”‚                 â”‚         â–¼           â”‚   â”‚ â”‚
â”‚  â”‚           â”‚                 â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚ â”‚
â”‚  â”‚           â”‚                 â”‚  â”‚     PVC       â”‚  â”‚   â”‚ â”‚
â”‚  â”‚           â”‚                 â”‚  â”‚ postgres-     â”‚  â”‚   â”‚ â”‚
â”‚  â”‚           â”‚                 â”‚  â”‚ storage-      â”‚  â”‚   â”‚ â”‚
â”‚  â”‚           â”‚                 â”‚  â”‚ postgres-0    â”‚  â”‚   â”‚ â”‚
â”‚  â”‚           â”‚                 â”‚  â”‚    (5Gi)      â”‚  â”‚   â”‚ â”‚
â”‚  â”‚           â”‚                 â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚ â”‚
â”‚  â”‚           â”‚                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ â”‚
â”‚  â”‚           â”‚                                           â”‚ â”‚
â”‚  â”‚           â–¼                          â–¼                â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚ â”‚
â”‚  â”‚  â”‚ web-service  â”‚         â”‚   db-service    â”‚       â”‚ â”‚
â”‚  â”‚  â”‚ NodePort     â”‚         â”‚   ClusterIP     â”‚       â”‚ â”‚
â”‚  â”‚  â”‚ :30085       â”‚         â”‚   :5432         â”‚       â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚ â”‚
â”‚  â”‚                                    â”‚                  â”‚ â”‚
â”‚  â”‚                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚ â”‚
â”‚  â”‚                           â”‚ postgres-      â”‚         â”‚ â”‚
â”‚  â”‚                           â”‚ headless       â”‚         â”‚ â”‚
â”‚  â”‚                           â”‚ (DNS stable)   â”‚         â”‚ â”‚
â”‚  â”‚                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Client Browser â”€â”€> NodePort :30085 â”€â”€> Web Pods â”€â”€> db-service â”€â”€> postgres-0
                                                         â”‚
                        Headless Service: postgres-0.postgres-headless...
```

### 11.4 Fichiers CrÃ©Ã©s/ModifiÃ©s

#### Nouveaux fichiers :
- `k8s/postgres-statefulset.yaml` - StatefulSet avec volumeClaimTemplates
- `k8s/postgres-headless-service.yaml` - Headless service (DNS stable)
- `k8s/postgres-service.yaml` - Service normal (load balancing)
- `scripts/test-statefulset.sh` - Script de test complet

#### Fichiers supprimÃ©s :
- ~~`k8s/db-pv.yaml`~~ - Plus nÃ©cessaire (auto-provisioning)
- ~~`k8s/db-pvc.yaml`~~ - Plus nÃ©cessaire (volumeClaimTemplates)
- ~~`k8s/db-deployment.yaml`~~ - RemplacÃ© par StatefulSet

#### Fichiers modifiÃ©s :
- `k8s/db-configmap.yaml` - POSTGRES_DB au lieu de MYSQL_DATABASE
- `k8s/db-secret.yaml` - POSTGRES_USER/PASSWORD au lieu de MYSQL
- `k8s/web-configmap.yaml` - Connexion PostgreSQL
- `scripts/install.sh` - Ordre de dÃ©ploiement adaptÃ©

### 11.5 StatefulSet PostgreSQL

#### `postgres-statefulset.yaml`

```yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: postgres
  namespace: lab5-app
spec:
  serviceName: "postgres-headless"    # RÃ©fÃ©rence au headless service
  replicas: 1                         # Peut scaler Ã  2-3
  selector:
    matchLabels:
      app: postgres
  template:
    metadata:
      labels:
        app: postgres
    spec:
      containers:
        - name: postgres
          image: postgres:15
          ports:
            - containerPort: 5432
              name: postgres
          env:
            - name: POSTGRES_DB
              valueFrom:
                configMapKeyRef:
                  name: db-config
                  key: POSTGRES_DB
            - name: POSTGRES_USER
              valueFrom:
                secretKeyRef:
                  name: db-secret
                  key: POSTGRES_USER
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: db-secret
                  key: POSTGRES_PASSWORD
            - name: PGDATA
              value: /var/lib/postgresql/data/pgdata
          volumeMounts:
            - name: postgres-storage
              mountPath: /var/lib/postgresql/data
  volumeClaimTemplates:               # Auto-crÃ©ation PVC
    - metadata:
        name: postgres-storage
      spec:
        accessModes: ["ReadWriteOnce"]
        storageClassName: "local-path"
        resources:
          requests:
            storage: 5Gi
```

**Points clÃ©s** :
- `serviceName`: Lien vers le headless service
- `volumeClaimTemplates`: CrÃ©e automatiquement `postgres-storage-postgres-0`
- `PGDATA`: Sous-rÃ©pertoire pour Ã©viter conflits de permissions

### 11.6 Headless Service

#### `postgres-headless-service.yaml`

```yaml
apiVersion: v1
kind: Service
metadata:
  name: postgres-headless
  namespace: lab5-app
spec:
  clusterIP: None                    # Headless !
  selector:
    app: postgres
  ports:
    - port: 5432
      targetPort: 5432
      name: postgres
```

**RÃ´le** : Fournit un DNS stable pour chaque pod :
- `postgres-0.postgres-headless.lab5-app.svc.cluster.local`
- `postgres-1.postgres-headless.lab5-app.svc.cluster.local`

### 11.7 Service Normal

#### `postgres-service.yaml`

```yaml
apiVersion: v1
kind: Service
metadata:
  name: db-service
  namespace: lab5-app
spec:
  type: ClusterIP
  selector:
    app: postgres
  ports:
    - port: 5432
      targetPort: 5432
```

**RÃ´le** : Load-balancing pour les applications (web app)

### 11.8 volumeClaimTemplates ExpliquÃ©

`volumeClaimTemplates` est la fonctionnalitÃ© clÃ© des StatefulSets :

#### Comment Ã§a fonctionne :

1. **CrÃ©ation automatique** : Pour chaque replica, Kubernetes crÃ©e un PVC
   ```
   Replica 0 â†’ postgres-storage-postgres-0 (5Gi)
   Replica 1 â†’ postgres-storage-postgres-1 (5Gi)
   Replica 2 â†’ postgres-storage-postgres-2 (5Gi)
   ```

2. **Binding automatique** : Chaque PVC est liÃ© au pod correspondant
   ```
   postgres-0 â†’ monte postgres-storage-postgres-0
   postgres-1 â†’ monte postgres-storage-postgres-1
   ```

3. **Persistance** : PVC survit mÃªme si :
   - Pod est supprimÃ©
   - StatefulSet est supprimÃ©
   - RÃ©plicas est rÃ©duit (scale down)

4. **RÃ©utilisation** : Si on scale up, les anciens PVC sont rÃ©utilisÃ©s
   ```bash
   kubectl scale statefulset postgres --replicas=0  # postgres-1 supprimÃ©
   kubectl scale statefulset postgres --replicas=2  # postgres-1 recrÃ©Ã© avec mÃªme PVC
   ```

#### Avantages vs PV/PVC manuels :

| Aspect | PV/PVC Manuel (LAB 5-7) | volumeClaimTemplates (LAB 8) |
|--------|-------------------------|------------------------------|
| CrÃ©ation | Manuelle (2 fichiers) | Automatique |
| Scaling | 1 PVC partagÃ© | 1 PVC par pod |
| Gestion | Erreurs possibles | ZÃ©ro configuration |
| Nettoyage | Manuel | Automatique mais retenu |

### 11.9 ProcÃ©dure de DÃ©ploiement LAB 8

```bash
# 1. Nettoyer l'ancien dÃ©ploiement (si LAB 5-7 existe)
kubectl delete namespace lab5-app

# 2. DÃ©ployer avec le script mis Ã  jour
cd ~/CloudContainerOrchestration/lab5-two-tier-app
sudo ./scripts/install.sh

# 3. VÃ©rifier le StatefulSet
kubectl get statefulset -n lab5-app
kubectl get pods -n lab5-app -l app=postgres

# 4. VÃ©rifier les PVCs auto-crÃ©Ã©s
kubectl get pvc -n lab5-app

# 5. Tester les DNS stables
kubectl run -n lab5-app dns-test --image=busybox:1.28 --rm -it -- \
  nslookup postgres-0.postgres-headless.lab5-app.svc.cluster.local

# 6. ExÃ©cuter les tests complets
sudo bash scripts/test-statefulset.sh
```

### 11.10 Tests de Validation

Le script `test-statefulset.sh` effectue 7 tests :

#### Test 1 : Nommage PrÃ©visible
```bash
kubectl get pods -n lab5-app -l app=postgres
# RÃ©sultat : postgres-0 (pas de suffixe alÃ©atoire)
```

#### Test 2 : DNS Stable
```bash
nslookup postgres-0.postgres-headless.lab5-app.svc.cluster.local
# RÃ©sultat : Adresse IP du pod postgres-0
```

#### Test 3 : PVC Automatique
```bash
kubectl get pvc -n lab5-app
# RÃ©sultat : postgres-storage-postgres-0 crÃ©Ã© automatiquement
```

#### Test 4 : Persistance des DonnÃ©es
```bash
# InsÃ©rer donnÃ©es
kubectl exec postgres-0 -- psql -U appuser -d appdb -c \
  "CREATE TABLE test (id INT, data VARCHAR(50));"
  
# Supprimer pod
kubectl delete pod postgres-0 -n lab5-app

# VÃ©rifier aprÃ¨s restart
kubectl exec postgres-0 -- psql -U appuser -d appdb -c \
  "SELECT * FROM test;"
# âœ“ DonnÃ©es toujours prÃ©sentes
```

#### Test 5 : IdentitÃ© Stable
```bash
# AprÃ¨s suppression, mÃªme nom
kubectl get pod postgres-0 -n lab5-app
# AGE rÃ©cent mais nom identique
```

#### Test 6 : Scaling SÃ©quentiel
```bash
kubectl scale statefulset postgres --replicas=3 -n lab5-app

# Ordre de crÃ©ation : postgres-0 â†’ postgres-1 â†’ postgres-2
# postgres-1 attend que postgres-0 soit Ready
```

#### Test 7 : Headless vs Regular Service
```bash
kubectl get svc -n lab5-app
# postgres-headless : ClusterIP None
# db-service : ClusterIP assignÃ©e
```

### 11.11 Scaling du StatefulSet

#### Scale Up (1 â†’ 3 replicas)

```bash
# Augmenter Ã  3 rÃ©plicas
kubectl scale statefulset postgres --replicas=3 -n lab5-app

# Observer la crÃ©ation sÃ©quentielle
kubectl get pods -n lab5-app -l app=postgres -w

# RÃ©sultat :
# postgres-0 : Running
# postgres-1 : PodInitializing (attend postgres-0)
# postgres-2 : Pending (attend postgres-1)

# VÃ©rifier les PVCs crÃ©Ã©s
kubectl get pvc -n lab5-app
# postgres-storage-postgres-0 (5Gi)
# postgres-storage-postgres-1 (5Gi)
# postgres-storage-postgres-2 (5Gi)
```

#### Scale Down (3 â†’ 1 replica)

```bash
# RÃ©duire Ã  1 replica
kubectl scale statefulset postgres --replicas=1 -n lab5-app

# Ordre de suppression : postgres-2 â†’ postgres-1
kubectl get pods -n lab5-app -l app=postgres -w

# âš ï¸ Les PVCs sont CONSERVÃ‰S
kubectl get pvc -n lab5-app
# postgres-storage-postgres-1 : Bound (mais non utilisÃ©)
# postgres-storage-postgres-2 : Bound (mais non utilisÃ©)
```

**Note** : PVCs retenues permettent de rescaler sans perte de donnÃ©es.

### 11.12 Configuration RÃ©plication (AvancÃ©)

Pour configurer PostgreSQL en mode Primary-Replica (futur LAB) :

```yaml
# postgres-0 = Primary (lecture/Ã©criture)
# postgres-1, postgres-2 = Replicas (lecture seule)

env:
  - name: POSTGRES_REPLICA_MODE
    value: "slave"
  - name: POSTGRES_MASTER_SERVICE
    value: "postgres-0.postgres-headless"
```

### 11.13 Rollback vers Deployment

Si nÃ©cessaire, pour revenir au Deployment :

```bash
# 1. Sauvegarder les donnÃ©es
kubectl exec postgres-0 -n lab5-app -- pg_dump -U appuser appdb > backup.sql

# 2. Supprimer StatefulSet
kubectl delete statefulset postgres -n lab5-app

# 3. RecrÃ©er Deployment
kubectl apply -f k8s/db-deployment-backup.yaml

# 4. Restaurer les donnÃ©es
kubectl exec db-deployment-xxx -n lab5-app -- psql -U appuser appdb < backup.sql
```

### 11.14 Comparaison Deployment vs StatefulSet

| CritÃ¨re | Deployment | StatefulSet |
|---------|-----------|-------------|
| **Noms pods** | `db-xxx-random` | `postgres-0, postgres-1` |
| **DNS** | AlÃ©atoire | Stable par pod |
| **Volume** | 1 PVC partagÃ© | 1 PVC par pod |
| **Ordre** | AlÃ©atoire | SÃ©quentiel |
| **Scaling** | ParallÃ¨le | OrdonnÃ© |
| **Use case** | Apps stateless | Bases de donnÃ©es, clusters |
| **RÃ©plication** | âŒ Impossible | âœ… Possible |
| **HA** | âŒ Difficile | âœ… Facile |

### 11.15 RÃ©sumÃ© des AmÃ©liorations LAB 8

âœ… **Migration MySQL â†’ PostgreSQL** : Meilleure performance et rÃ©plication  
âœ… **Deployment â†’ StatefulSet** : IdentitÃ© et ordre garantis  
âœ… **volumeClaimTemplates** : Auto-provisioning des PVCs  
âœ… **Headless Service** : DNS stable par pod  
âœ… **Ready pour HA** : Base pour rÃ©plication master-slave  
âœ… **Scripts de test** : Validation automatisÃ©e  
âœ… **Production-ready** : Suit les best practices Kubernetes

---

## 12. AccÃ¨s et Validation Finale
