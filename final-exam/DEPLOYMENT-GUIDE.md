# Guide de D√©ploiement - Coexistence Challenge Lab & Final Exam

## üéØ Objectif

D√©ployer **Challenge Lab** et **Final Exam** sur la **m√™me VM K3s** sans conflits.

---

## ‚úÖ Analyse des Conflits Potentiels

### 1. Namespaces (Pas de conflit)
- ‚úÖ **Challenge Lab**: `three-tier-app`
- ‚úÖ **Final Exam**: `final-exam`
- **Isolation garantie** par Kubernetes

### 2. NodePorts (Pas de conflit)
- ‚úÖ **Challenge Lab**: Port `30080`
- ‚úÖ **Final Exam**: Port `30090`
- **Ports diff√©rents** - pas de collision

### 3. Ressources VM (‚ö†Ô∏è Conflit possible)

#### Storage (PVCs)
| Application | PVCs | Taille totale |
|------------|------|---------------|
| Challenge Lab | 6 (PostgreSQL 3 replicas √ó 2) | ~30 Gi |
| Final Exam (Full) | 12 (PostgreSQL 3√ó2 + MongoDB 3√ó2) | ~60 Gi |
| **TOTAL** | **18** | **~90 Gi** |

#### CPU/Memory
| Application | Pods | CPU min | Memory min |
|------------|------|---------|------------|
| Challenge Lab | 6-8 | ~1.5 vCPU | ~2 GB |
| Final Exam (Full) | 10-14 | ~2.5 vCPU | ~3 GB |
| **TOTAL** | **16-22** | **~4 vCPU** | **~5-6 GB** |

---

## üîç √âtape 1: V√©rifier les Ressources de la VM

### Option A: Sur votre machine locale
```bash
# SSH vers la VM
ssh mohamed@10.174.154.67

# Ex√©cuter le script de v√©rification
cd final-exam
chmod +x scripts/check-vm-resources.sh
./scripts/check-vm-resources.sh
```

### Option B: Commandes manuelles sur la VM
```bash
# V√©rifier CPU et m√©moire
kubectl top nodes
free -h
lscpu | grep "CPU(s)"

# V√©rifier storage disponible
df -h /var/lib/rancher/k3s

# V√©rifier d√©ploiements existants
kubectl get all --all-namespaces
kubectl get pvc --all-namespaces
```

### Crit√®res de D√©cision

| Ressource VM | D√©ploiement Recommand√© |
|--------------|------------------------|
| **CPU: 4+ cores, RAM: 8+ GB, Storage: 100+ Gi** | ‚úÖ **Sc√©nario 1**: Les deux apps en full mode |
| **CPU: 2-3 cores, RAM: 4-6 GB, Storage: 50-80 Gi** | ‚ö†Ô∏è **Sc√©nario 2**: Final Exam en mode minimal |
| **CPU: 2 cores, RAM: 4 GB, Storage: <50 Gi** | üö® **Sc√©nario 3**: Une seule app √† la fois |

---

## üì¶ Sc√©nario 1: VM Puissante (Recommand√©)

### Conditions
- ‚úÖ CPU: 4+ cores
- ‚úÖ RAM: 8+ GB
- ‚úÖ Storage: 100+ Gi disponibles

### D√©ploiement
```bash
# Challenge Lab d√©j√† d√©ploy√© sur namespace three-tier-app
# Accessible sur http://10.174.154.67:30080

# D√©ployer Final Exam en mode complet
cd final-exam
./scripts/install.sh

# V√©rifier les deux applications
kubectl get pods -n three-tier-app
kubectl get pods -n final-exam

# Acc√®s
# Challenge Lab: http://10.174.154.67:30080
# Final Exam:    http://10.174.154.67:30090
```

### Avantages
- ‚úÖ Haute disponibilit√© (3 replicas DB)
- ‚úÖ Les deux apps ind√©pendantes
- ‚úÖ D√©monstration compl√®te

---

## ‚öôÔ∏è Sc√©nario 2: VM Moyenne (Mode Minimal)

### Conditions
- ‚ö†Ô∏è CPU: 2-3 cores
- ‚ö†Ô∏è RAM: 4-6 GB
- ‚ö†Ô∏è Storage: 50-80 Gi

### D√©ploiement avec R√©duction
```bash
# Challenge Lab reste en mode complet (d√©j√† d√©ploy√©)

# D√©ployer Final Exam avec 1 replica par DB
cd final-exam
./scripts/install-minimal.sh

# Ce script r√©duit automatiquement:
# - MongoDB: 3 replicas ‚Üí 1 replica
# - PostgreSQL: 3 replicas ‚Üí 1 replica
# - √âconomie: 50 Gi storage, ~40% CPU/RAM
```

### Comparaison

| Ressource | Mode Full | Mode Minimal | √âconomie |
|-----------|-----------|--------------|----------|
| PVCs Final Exam | 12 | 2 | -10 PVCs |
| Storage Final Exam | 60 Gi | 10 Gi | -50 Gi |
| Pods Final Exam | 10-14 | 6-8 | -40% |

### Avantages
- ‚úÖ Les deux apps fonctionnelles
- ‚úÖ Ressources partag√©es efficacement
- ‚ö†Ô∏è Final Exam sans HA (acceptable pour d√©mo)

---

## üîÑ Sc√©nario 3: VM Limit√©e (D√©ploiement S√©quentiel)

### Conditions
- üö® CPU: 2 cores
- üö® RAM: 4 GB
- üö® Storage: <50 Gi

### Option A: Supprimer Challenge Lab puis d√©ployer Final Exam
```bash
# Sauvegarder les screenshots du Challenge Lab
# Puis supprimer
kubectl delete namespace three-tier-app

# Lib√®re:
# - 6 PVCs √ó 5Gi = 30 Gi
# - 6-8 pods
# - ~1.5 vCPU, ~2 GB RAM

# D√©ployer Final Exam
cd final-exam
./scripts/install.sh

# Acc√®s: http://10.174.154.67:30090
```

### Option B: Garder Challenge Lab, d√©ployer Final Exam temporairement
```bash
# D√©ployer Final Exam en mode minimal
cd final-exam
./scripts/install-minimal.sh

# Tester et prendre screenshots

# Supprimer Final Exam
kubectl delete namespace final-exam

# Challenge Lab reste accessible sur 30080
```

---

## üß™ Tests de Coexistence

### 1. V√©rifier les deux applications
```bash
# Challenge Lab
curl http://10.174.154.67:30080
kubectl get pods -n three-tier-app

# Final Exam
curl http://10.174.154.67:30090
kubectl get pods -n final-exam
```

### 2. Tester l'isolation des namespaces
```bash
# Les services sont isol√©s
kubectl get svc -n three-tier-app
kubectl get svc -n final-exam

# Les PVCs sont s√©par√©s
kubectl get pvc -n three-tier-app
kubectl get pvc -n final-exam
```

### 3. V√©rifier les ressources
```bash
# √âtat global
kubectl get all --all-namespaces
kubectl top nodes
kubectl top pods --all-namespaces
```

### 4. Test de charge (optionnel)
```bash
# Challenge Lab
ab -n 100 -c 5 http://10.174.154.67:30080/

# Final Exam
ab -n 100 -c 5 http://10.174.154.67:30090/

# V√©rifier HPA scaling
watch kubectl get hpa --all-namespaces
```

---

## üì∏ Plan de Capture Screenshots

### Challenge Lab (30080)
1. Frontend - Liste de t√¢ches
2. kubectl get all -n three-tier-app
3. kubectl get pvc -n three-tier-app
4. HPA status

### Final Exam (30090)
1. Frontend - Liste de t√¢ches
2. Analytics Dashboard (apr√®s impl√©mentation)
3. kubectl get all -n final-exam
4. kubectl get pvc -n final-exam
5. Test microservices output
6. Logs montrant communication inter-services

### Coexistence
1. `kubectl get all --all-namespaces`
2. `kubectl top nodes`
3. Both apps accessible (split screen browser)

---

## üÜò Troubleshooting

### Probl√®me: Pods en Pending
```bash
# V√©rifier les √©v√©nements
kubectl get events -n final-exam --sort-by='.lastTimestamp'

# Cause probable: Storage ou CPU insuffisant
kubectl describe pod <pod-name> -n final-exam

# Solution: Mode minimal ou suppression Challenge Lab
./scripts/install-minimal.sh
```

### Probl√®me: PVC Pending
```bash
# V√©rifier PVCs
kubectl get pvc --all-namespaces

# V√©rifier storage disponible sur VM
df -h /var/lib/rancher/k3s

# Si plein: Supprimer une application
kubectl delete namespace three-tier-app
```

### Probl√®me: OOMKilled (Out of Memory)
```bash
# Identifier le pod
kubectl get pods -n final-exam | grep OOMKilled

# R√©duire les replicas
kubectl scale deployment backend-api --replicas=1 -n final-exam
kubectl scale deployment analytics --replicas=1 -n final-exam
```

---

## üéØ Recommandation Finale

### Pour une D√©mo Compl√®te
1. **V√©rifier ressources VM**: `./scripts/check-vm-resources.sh`
2. **Si ressources OK (4+ vCPU, 8+ GB)**: D√©ployer les deux en full mode
3. **Si ressources limit√©es**: Final Exam en mode minimal
4. **Si tr√®s limit√©**: D√©ployer s√©quentiellement (prendre screenshots puis cleanup)

### Ordre de D√©ploiement Optimal
```bash
# 1. Challenge Lab (d√©j√† fait)
# 2. V√©rifier ressources
ssh mohamed@10.174.154.67
cd final-exam
./scripts/check-vm-resources.sh

# 3a. Si ressources OK
./scripts/install.sh

# 3b. Si ressources limit√©es
./scripts/install-minimal.sh

# 4. Tests
./scripts/health-check.sh
./scripts/test-microservices.sh

# 5. Screenshots des deux apps

# 6. Cleanup optionnel apr√®s d√©mo
kubectl delete namespace final-exam
# Ou
kubectl delete namespace three-tier-app
```

---

## üìä Matrice de D√©cision Rapide

| VM Specs | Action | Challenge Lab | Final Exam | Total Pods |
|----------|--------|---------------|------------|------------|
| 4+ vCPU, 8+ GB, 100+ Gi | ‚úÖ Les deux full | 3 replicas | 3 replicas | 16-22 |
| 2-3 vCPU, 4-6 GB, 50-80 Gi | ‚ö†Ô∏è Final minimal | 3 replicas | 1 replica | 12-16 |
| 2 vCPU, 4 GB, <50 Gi | üö® S√©quentiel | OU | OU | 6-10 |

---

**Conclusion**: Les deux applications **peuvent coexister** sur la m√™me VM gr√¢ce √†:
- ‚úÖ Namespaces s√©par√©s
- ‚úÖ NodePorts diff√©rents (30080 vs 30090)
- ‚úÖ Mode minimal si ressources limit√©es
- ‚úÖ Scripts de v√©rification et d√©ploiement flexibles
